{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import logging\n",
    "import os\n",
    "import shelve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from gensim import corpora, models\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import metrics\n",
    "\n",
    "from nltools.exceptions import WrongExtensionError\n",
    "from nltools.streams.io_.basic import read_csv\n",
    "from nltools.streams.preprocessing import basic as basic_prp\n",
    "from nltools.streams.preprocessing.preloading import stop_words\n",
    "from nltools.streams.preprocessing import w2v\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stop_words=None, min_len=1):\n",
    "    text = basic_prp.clean_text(text)\n",
    "    return basic_prp.tokenize(text, stop_words, min_len)\n",
    "\n",
    "\n",
    "def tm_preprocess(text, stop_words=None, min_len=1):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    return [basic_prp.lemmatize(i, morph) for i preprocess(text, stop_words=stop_words, min_len=min_len)]\n",
    "\n",
    "\n",
    "def read_preprocess(input_file, mode):\n",
    "    if mode == 'd2v':\n",
    "        cur_document = [preprocess(line, stop_words=stop_words, min_len=0) for *_, line in read_csv(f'tg_data/{input_file}', msg_brd=None)]            \n",
    "        return list(itertools.chain(*cur_document)), [input_file]\n",
    "    \n",
    "    elif mode == 'tm':\n",
    "        cur_document = [tm_preprocess(line, stop_words=stop_words, min_len=0) for *_, line in read_csv(f'tg_data/{input_file}', msg_brd=None)]            \n",
    "        return list(itertools.chain(*cur_document))\n",
    "\n",
    "\n",
    "def read_preprocess_multi(input_files,\n",
    "                          prp_mode,\n",
    "                          batch_size=5, \n",
    "                          workers=5,\n",
    "                          db_name='temp.db',\n",
    "                          res_var_name='train_corpus'):\n",
    "    for i in range(0, len(input_files), batch_size):\n",
    "        print(f'\\rPreprocessing files {i}-{i+batch_size}.', end='')\n",
    "        pool = Pool(processes=workers)\n",
    "        batch = list(pool.map(lambda x: d2v_read_preprocess(x, prp_mode), input_files[i:i+batch_size]))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        with shelve.open(db_name) as db:\n",
    "            try:\n",
    "                temp = db[res_var_name]\n",
    "            except KeyError:\n",
    "                db[res_var_name] = batch\n",
    "                continue\n",
    "\n",
    "            temp += batch\n",
    "            db[res_var_name] = temp\n",
    "            del temp, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "read_preprocess_multi(list(os.listdir('tg_data/')), \n",
    "                      'd2v',\n",
    "                      db_name='objs/temp-d2v.db', \n",
    "                      res_var_name='train_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_preprocess_multi(list(os.listdir('tg_data/')), \n",
    "                      'tm',\n",
    "                      db_name='objs/temp-d2v.db', \n",
    "                      res_var_name='train_corpus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение предобработанных данных для D2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShelveReader:\n",
    "    def __init__(self, filenames, mode='td'):\n",
    "        self.filenames = filenames\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for fn in self.filenames:\n",
    "            with shelve.open(fn) as db:\n",
    "                for doc, label in db[list(db.keys())[0]]:\n",
    "                    if self.mode == 'td':\n",
    "                        yield TaggedDocument(doc, label)  \n",
    "                    elif self.mode == 'asis':\n",
    "                        yield doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = [doc for doc in ShelveReader(['objs/temp.db'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec\n",
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Doc2Vec(vector_size=100, dbow_words=1, min_count=2, window=10, sample=1e-3, workers=3, seed=42)\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train(train_corpus, \n",
    "            total_examples=model.corpus_count, \n",
    "            epochs=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка на вменяемость для Doc2Vec модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranks(train_corpus):\n",
    "    ranks = []\n",
    "\n",
    "    for doc in train_corpus:\n",
    "        inferred_vector = model.infer_vector(doc.words)\n",
    "        sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "        rank = [docid for docid, sim in sims].index(doc.tags[0])\n",
    "        ranks.append(rank)\n",
    "    \n",
    "    return collections.Counter(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_ranks(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('d2v-215')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка результатов векторизации путем проведения кластеризации и отрисовки векторов в сжатом пространстве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_df = pd.read_csv('mu/ds_true.csv')\n",
    "true_labels = [j-1 for i in range(len(true_labels_df)) for j, el in enumerate(true_labels_df.iloc[i]) if el == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load('objs/d2v-215')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = []\n",
    "\n",
    "for fname in true_labels_df['dump_id']:\n",
    "    doc_vectors.append(model.docvecs[fname].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "pred_labels = kmeans.fit_predict(model.docvecs.vectors_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.fowlkes_mallows_score(true_labels, pred_labels)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Doc2Vec(vector_size=50, min_count=2, sample=1e-5, workers=4) -- 0.14086823960956465\n",
    "\n",
    "model = Doc2Vec(vector_size=400, min_count=2, window=6, sample=1e-5, workers=4) -- 0.14888268334614022\n",
    "\n",
    "model = Doc2Vec(vector_size=400, min_count=2, window=6, sample=1e-6, workers=4) -- 0.18628878806361712\n",
    "\n",
    "model = Doc2Vec(vector_size=400, min_count=2, window=3, sample=1e-6, workers=4) -- 0.177933197245823\n",
    "\n",
    "model = Doc2Vec(vector_size=400, min_count=2, window=10, sample=1e-6, workers=4) -- 0.21118463712915594\n",
    "\n",
    "model = Doc2Vec(vector_size=400, min_count=2, window=10, sample=1e-7, workers=4) -- 0.15144894062234954\n",
    "\n",
    "model = Doc2Vec(vector_size=400, dm=0, min_count=2, window=10, sample=1e-6, workers=4) -- 0.1635102868186538\n",
    "\n",
    "model = Doc2Vec(vector_size=400, dbow_words=1, min_count=2, window=10, sample=1e-6, workers=4) -- 0.21547558866834945\n",
    "\n",
    "model = Doc2Vec(vector_size=400, negative=10, dbow_words=1, min_count=1, window=10, sample=1e-6, workers=4) -- 0.13814767369837347"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отрисовка векторов (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(model.docvecs.vectors_docs)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=true_labels, cmap='jet')\n",
    "\n",
    "for label, x, y in zip(pred_labels, X[:, 0], X[:, 1]):\n",
    "    plt.annotate(label, xy=(x, y))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отрисовка векторов (TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = TSNE(n_components=2).fit_transform(model.docvecs.vectors_docs)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=true_labels, cmap='jet')\n",
    "\n",
    "for label, x, y in zip(pred_labels, X[:, 0], X[:, 1]):\n",
    "    plt.annotate(label, xy=(x, y))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, X, train_corpus, true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тематическое моделирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = [doc for doc in ShelveReader(['objs/temp.db'], mode='asis')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dct = corpora.Dictionary(train_corpus)\n",
    "corpus = [dct.doc2bow(line) for line in train_corpus]\n",
    "tfidf = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(corpus_tfidf, id2word=dct, num_topics=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.print_topics(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_cluster = [i for i in range(len(labels)) if labels[i] == 2]\n",
    "\n",
    "# # for i in test_cluster:\n",
    "# #     print(f'i:{i} {vld.iloc[i][\"IT\"]}')\n",
    "# for i in range(43):\n",
    "#     print(f'{labels[i]}')\n",
    "# collections.Counter(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
